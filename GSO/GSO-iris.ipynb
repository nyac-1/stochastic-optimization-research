{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer import *\n",
    "\n",
    "from __future__ import division\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(load_iris().data)\n",
    "y = np.vectorize(lambda x: 1 if(x>0) else 0)(load_iris().target).astype(np.float64)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state=10, stratify=y)\n",
    "X_train = np.transpose(X_train)\n",
    "X_test = np.transpose(X_test)\n",
    "y_train = y_train.reshape(1,-1)\n",
    "y_test = y_test.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_best_position\n",
    "global global_best_cost\n",
    "\n",
    "class Particle:\n",
    "    global input_size\n",
    "    global computational_layer\n",
    "    global ouput_layer\n",
    "    \n",
    "    def __init__(self, dimensions):\n",
    "        self.position = np.random.random((dimensions,))\n",
    "        self.dimensions = dimensions\n",
    "        self.position_bounds = [-10,10]\n",
    "        self.velocity_bounds = [(self.position_bounds[1]-self.position_bounds[0])/2, -1 * self.position_bounds[1]]\n",
    "        self.velocity = np.random.random((dimensions,))\n",
    "        self.best_position = np.random.random((dimensions,))\n",
    "        self.best_cost, _ = forward_pass_weights_bin(self.best_position,X_train, y_train ,input_size, computational_layer, output_layer)\n",
    "        \n",
    "        self.c = [2.05,2.05]\n",
    "        self.learning_rate = 0.8\n",
    "        \n",
    "    def evaluate(self, cost):\n",
    "        if(cost<self.best_cost):\n",
    "            self.best_cost = cost\n",
    "            self.best_position = self.position\n",
    "    \n",
    "    def update_velocity(self, swarm_best_position, omega):\n",
    "        self.velocity = omega * (self.velocity) + (self.c[0]*(2.0*random.random()-1.0)*(self.best_position - self.position)) + (self.c[1]*(2.0*random.random()-1.0)*(swarm_best_position - self.position))\n",
    "        \n",
    "    def update_position(self):\n",
    "        self.position = self.position + self.velocity\n",
    "        self.position = np.vectorize(lambda z: self.position_bounds[1] if z > self.position_bounds[1] else float(z)) (self.position)\n",
    "        self.position = np.vectorize(lambda z: self.position_bounds[0] if z < self.position_bounds[0] else float(z)) (self.position)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swarm:\n",
    "    global input_size\n",
    "    global computational_layer\n",
    "    global output_layer\n",
    "    \n",
    "    def __init__(self, dimensions, n_population):\n",
    "        self.particles = [Particle(dimensions) for x in range(n_population)]\n",
    "        self.swarm_best_particle = self.particles[0]\n",
    "        self.swarm_best_position = self.particles[0].position\n",
    "        self.swarm_best_cost, _ = forward_pass_weights_bin(self.swarm_best_position,X_train, y_train ,input_size, computational_layer, output_layer)\n",
    "    \n",
    "    def run_n_iterations(self, n_iterations):\n",
    "        for iteration in range(n_iterations+1):\n",
    "            omega = float(1.0-(iteration/(n_iterations+1)))\n",
    "            \n",
    "            for particle in self.particles:\n",
    "                particle.update_velocity(self.swarm_best_position, omega)\n",
    "                particle.update_position()\n",
    "            \n",
    "            for particle in self.particles:\n",
    "                \n",
    "                cost, _ = forward_pass_weights_bin(particle.position,X_train, y_train ,input_size, computational_layer, output_layer)\n",
    "                \n",
    "                particle.evaluate(cost)\n",
    "                if(cost<self.swarm_best_cost):\n",
    "                    self.swarm_best_cost = cost\n",
    "                    self.swarm_best_position = particle.position\n",
    "                    self.swarm_best_particle = particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "computational_layer = 5\n",
    "output_layer = 1\n",
    "dimensions = calculate_dimensions(input_size, computational_layer, output_layer)\n",
    "\n",
    "n_particles = 80\n",
    "n_swarms = 10\n",
    "dimensions = calculate_dimensions(input_size, computational_layer, output_layer)\n",
    "l1 = 150\n",
    "l2 = 300\n",
    "\n",
    "subswarms = [Swarm(dimensions, n_particles) for x in range(n_swarms)]\n",
    "collection_best = Swarm(dimensions, n_swarms)\n",
    "\n",
    "epochs = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sampathroutu/Desktop/research/stochastic-optimization-research/GSO/layer.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  sigmoid = lambda z: float(1/(1 + np.exp(-z)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.97057390213013\n",
      "0.43989018519879686\n",
      "9.390168136914067e-307\n",
      "9.4567527583476e-155\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for subswarm in subswarms:\n",
    "        subswarm.run_n_iterations(l1)\n",
    "\n",
    "    collection_best.particles = [subswarm.swarm_best_particle for subswarm in subswarms]\n",
    "    collection_best.run_n_iterations(l2)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "cost, output = forward_pass_weights_bin(collection_best.swarm_best_position,X_train,y_train,input_size, computational_layer, output_layer)\n",
    "print(cost)\n",
    "print(reg_cost(y_train, output))\n",
    "print(mae(y_train, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43989018519879713\n",
      "0.0\n",
      "1.7585295260270084e-287\n"
     ]
    }
   ],
   "source": [
    "cost, output = forward_pass_weights_bin(collection_best.swarm_best_position,X_test,y_test,input_size, computational_layer, output_layer)\n",
    "print(cost)\n",
    "print(reg_cost(y_test, output))\n",
    "print(mae(y_test, output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43989018519879713"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost, output = forward_pass_weights_bin(collection_best.swarm_best_position,X_test,y_test,input_size, computational_layer, output_layer)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
